{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as op\n",
    "op.download(\"https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf                                                               # библиотека Tensorflow\n",
    "import keras                                                                          # библиотека Keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, ReLU, Rescaling     # cлои библиотеки Keras\n",
    "from keras.layers import BatchNormalization, Conv2DTranspose, Concatenate             # cлои библиотеки Keras\n",
    "from keras.layers import Rescaling, Resizing                                          # cлои библиотеки Keras\n",
    "from keras.models import Model, Sequential                                            # конструкторы построения моделей библиотеки Keras\n",
    "\n",
    "from keras.optimizers import Adam                                                     # оптимизатор Adam\n",
    "from keras.utils import to_categorical                                                # преобразует вектор класса (целые числа) в двоичную матрицу класса\n",
    "\n",
    "import numpy as np                                                                    # библиотека линейной алгебры\n",
    "import pandas as pd                                                                   # библиотека обработки табличных данных\n",
    "import os                                                                             # библиотека работы с функциями операционной системы, в том числе с файлами\n",
    "import albumentations as A                                                            # библиотека аугментации изображений (https://albumentations.ai/)\n",
    "\n",
    "import matplotlib.pyplot as plt                                                       # библиотека для рисования графиков\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import skimage.io                           #Used for imshow function\n",
    "import skimage.transform                    #Used for resize function\n",
    "from skimage.morphology import label        #Used for Run-Length-Encoding RLE to create final submission\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, target_size=(192, 192)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img = img_to_array(img) / 255.0\n",
    "    return img\n",
    "\n",
    "def load_mask(mask_path, target_size=(192, 192)):\n",
    "    mask = load_img(mask_path, target_size=target_size, color_mode=\"grayscale\")\n",
    "    mask = img_to_array(mask) / 255.0\n",
    "    return mask\n",
    "\n",
    "def image_mask_generator(image_paths, mask_paths, batch_size):\n",
    "    while True:\n",
    "        idx = np.random.permutation(len(image_paths))\n",
    "        image_paths = np.array(image_paths)[idx]\n",
    "        mask_paths = np.array(mask_paths)[idx]\n",
    "\n",
    "        for i in range(0, len(image_paths), batch_size):\n",
    "            batch_images = image_paths[i:i + batch_size]\n",
    "            batch_masks = mask_paths[i:i + batch_size]\n",
    "\n",
    "            images = np.array([load_image(img_path) for img_path in batch_images])\n",
    "            masks = np.array([load_mask(mask_path) for mask_path in batch_masks])\n",
    "\n",
    "            yield images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/content/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/images'\n",
    "label_dir = '/content/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/masks'\n",
    "\n",
    "image_paths = [os.path.join(image_dir, img) for img in os.listdir(image_dir)]\n",
    "mask_paths = [os.path.join(label_dir, msk) for msk in os.listdir(label_dir)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_paths, mask_paths, test_size=0.25, random_state=42)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_gen = image_mask_generator(X_train, y_train, batch_size=batch_size)\n",
    "val_gen = image_mask_generator(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция свертки\n",
    "def convolution_operation(entered_input, filters=64):\n",
    "    conv1 = Conv2D(filters, kernel_size=(3, 3), padding=\"same\")(entered_input)\n",
    "    batch_norm1 = BatchNormalization()(conv1)\n",
    "    acti1 = ReLU()(batch_norm1)\n",
    "\n",
    "    conv2 = Conv2D(filters, kernel_size=(3, 3), padding=\"same\")(acti1)\n",
    "    batch_norm2 = BatchNormalization()(conv2)\n",
    "    acti2 = ReLU()(batch_norm2)\n",
    "\n",
    "    return acti2\n",
    "\n",
    "# Латеральное соединение\n",
    "def dense_skip_connection(encoder_output, skip_output, filters, depth):\n",
    "    for i in range(depth):\n",
    "        skip_output = convolution_operation(skip_output, filters)\n",
    "        skip_output = Concatenate()([skip_output, encoder_output])\n",
    "    return skip_output\n",
    "\n",
    "# Кодировщик\n",
    "def encoder(entered_input, filters=64):\n",
    "    encod1 = convolution_operation(entered_input, filters)\n",
    "    MaxPool1 = MaxPooling2D(strides=(2, 2))(encod1)\n",
    "    return encod1, MaxPool1\n",
    "\n",
    "# Декодировщик\n",
    "def decoder(entered_input, skip, filters=64, depth=2):\n",
    "    Upsample = Conv2DTranspose(filters, (2, 2), strides=2, padding=\"same\")(entered_input)\n",
    "    skip = dense_skip_connection(skip, skip, filters, depth)\n",
    "    Connect_Skip = Concatenate()([Upsample, skip])\n",
    "    out = convolution_operation(Connect_Skip, filters)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель U-Net++\n",
    "def U_NetPP(img_size, num_classes, deep_supervision=True):\n",
    "    inputs = Input(img_size)\n",
    "\n",
    "    # Кодировщик\n",
    "    skip1, encoder_1 = encoder(inputs, 64)\n",
    "    skip2, encoder_2 = encoder(encoder_1, 64*2)\n",
    "    skip3, encoder_3 = encoder(encoder_2, 64*4)\n",
    "    skip4, encoder_4 = encoder(encoder_3, 64*8)\n",
    "\n",
    "    # Латентное пространство\n",
    "    conv_block = convolution_operation(encoder_4, 64*16)\n",
    "\n",
    "    # Декодировщик с плотными скип-соединениями (dense skip connections)\n",
    "    decoder_1 = decoder(conv_block, skip4, 64*8, depth=3)\n",
    "    decoder_2 = decoder(decoder_1, skip3, 64*4, depth=2)\n",
    "    decoder_3 = decoder(decoder_2, skip2, 64*2, depth=1)\n",
    "    decoder_4 = decoder(decoder_3, skip1, 64, depth=1)\n",
    "\n",
    "    # Глубокая супервизия\n",
    "    if deep_supervision:\n",
    "        output1 = Conv2D(num_classes, (1, 1), padding=\"same\", activation=\"sigmoid\")(decoder_1)\n",
    "        output2 = Conv2D(num_classes, (1, 1), padding=\"same\", activation=\"sigmoid\")(decoder_2)\n",
    "        output3 = Conv2D(num_classes, (1, 1), padding=\"same\", activation=\"sigmoid\")(decoder_3)\n",
    "        output4 = Conv2D(num_classes, (1, 1), padding=\"same\", activation=\"sigmoid\")(decoder_4)\n",
    "\n",
    "        # Приводим все выходы к одному размеру\n",
    "        output1 = UpSampling2D(size=(8, 8))(output1)\n",
    "        output2 = UpSampling2D(size=(4, 4))(output2)\n",
    "        output3 = UpSampling2D(size=(2, 2))(output3)\n",
    "\n",
    "        # Среднее объединение выходов при супервизиях\n",
    "        outputs = tf.keras.layers.Average()([output1, output2, output3, output4])\n",
    "    else:\n",
    "        # Один финальный выход (без супервизии)\n",
    "        outputs = Conv2D(num_classes, (1, 1), padding=\"same\", activation=\"sigmoid\")(decoder_4)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (192, 192, 3)\n",
    "num_classes = 1\n",
    "\n",
    "\n",
    "model = U_NetPP(input_shape, num_classes, deep_supervision=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"unetpp_deep_supervision.keras\", monitor='val_loss', save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    validation_steps=len(X_test) // batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']                              # данные о точности на обучающей выборке\n",
    "val_acc = history.history['val_accuracy']                      # данные о точности на проверочной выборке\n",
    "loss = history.history['loss']                                             # данные об ошибке на обучающей выборке\n",
    "val_loss = history.history['val_loss']                                     # данные об ошибке на проверочной выборке\n",
    "epochs = range(1, len(acc) + 1)                                            # массив со значениями для оси абсцисс (Х)\n",
    "plt.plot(epochs, acc, 'r', label='Точность на обучающей выборке')          #  строим график точность на обучающей выборке\n",
    "plt.plot(epochs, val_acc, 'bo', label='Точность на проверочной выборке')   #  строим график точность на проверочной выборке\n",
    "plt.title('График точности на обучающей и проверочной выборках')           #  заголовок графика\n",
    "plt.legend()                                                               #  легенда графика\n",
    "plt.figure()                                                               #  создаем новую фигуру (полотно для графика)\n",
    "plt.plot(epochs, loss, 'r', label='Потери на обучающей выборке')           #  строим график потерь (ошибки) на обучающей выборке\n",
    "plt.plot(epochs, val_loss, 'bo', label='Потери на валидационной выборке')  #  строим график потерь на проверочной выборке\n",
    "plt.title('График потерь на обучающей и проверочной выборках')             #  заголовок графика\n",
    "plt.legend()                                                               #  легенда графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_multiple_results(images, true_masks, pred_masks, num_images=10):\n",
    "    plt.figure(figsize=(15, num_images * 5))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Входное изображение\n",
    "        plt.subplot(num_images, 3, i * 3 + 1)\n",
    "        plt.title(f'Входное изображение {i+1}')\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Оригинальная маска\n",
    "        plt.subplot(num_images, 3, i * 3 + 2)\n",
    "        plt.title(f'Оригинальная маска {i+1}')\n",
    "        plt.imshow(images[i])\n",
    "        plt.imshow(true_masks[i], alpha=0.8)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Предсказанная маска\n",
    "        plt.subplot(num_images, 3, i * 3 + 3)\n",
    "        plt.title(f'Предсказанная маска {i+1}')\n",
    "        plt.imshow(images[i])\n",
    "        plt.imshow(pred_masks[i], alpha=0.8)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 10\n",
    "sample_images = [load_image(X_test[i]) for i in range(num_images)]\n",
    "sample_masks = [load_mask(y_test[i]) for i in range(num_images)]\n",
    "predicted_masks = [model.predict(sample_images[i][np.newaxis, ...])[0] for i in range(num_images)]\n",
    "display_multiple_results(sample_images, sample_masks, predicted_masks, num_images=num_images)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
